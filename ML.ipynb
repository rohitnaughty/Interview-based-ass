{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23308f90-ebc7-4daf-be6a-590ffd3ee0a8",
   "metadata": {},
   "source": [
    "Q-1. Imagine you have a dataset where you have different Instagram features like u sername , Caption , Hashtag , Followers , Time_Since_posted , and likes , now your task is to predict the number of likes and Time Since posted and the rest of the features are your input features. Now you have to build a model which can predict the number of likes and Time Since posted. Dataset This is the Dataset You can use this dataset for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24fc32c1-0796-46bf-a834-4b0f8681a1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cc09f46-17ae-468e-9858-692dedbcd665",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"instagram_reach.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a27b855-f90f-48fa-99d7-10a5c3ca9413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>S.No</th>\n",
       "      <th>USERNAME</th>\n",
       "      <th>Caption</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Time since posted</th>\n",
       "      <th>Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>mikequindazzi</td>\n",
       "      <td>Who are #DataScientist and what do they do? &gt;&gt;...</td>\n",
       "      <td>1600</td>\n",
       "      <td>#MachineLearning #AI #DataAnalytics #DataScien...</td>\n",
       "      <td>11 hours</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>drgorillapaints</td>\n",
       "      <td>We all know where it’s going. We just have to ...</td>\n",
       "      <td>880</td>\n",
       "      <td>#deck .#mac #macintosh#sayhello #apple #steve...</td>\n",
       "      <td>2 hours</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>aitrading_official</td>\n",
       "      <td>Alexander Barinov: 4 years as CFO in multinati...</td>\n",
       "      <td>255</td>\n",
       "      <td>#whoiswho #aitrading #ai #aitradingteam#instat...</td>\n",
       "      <td>2 hours</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>opensourcedworkplace</td>\n",
       "      <td>sfad</td>\n",
       "      <td>340</td>\n",
       "      <td>#iot #cre#workplace #CDO #bigdata #technology#...</td>\n",
       "      <td>3 hours</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>crea.vision</td>\n",
       "      <td>Ever missed a call while your phone was chargi...</td>\n",
       "      <td>304</td>\n",
       "      <td>#instamachinelearning #instabigdata#instamarke...</td>\n",
       "      <td>3 hours</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  S.No              USERNAME  \\\n",
       "0           0     1         mikequindazzi   \n",
       "1           1     2       drgorillapaints   \n",
       "2           2     3    aitrading_official   \n",
       "3           3     4  opensourcedworkplace   \n",
       "4           4     5           crea.vision   \n",
       "\n",
       "                                             Caption  Followers  \\\n",
       "0  Who are #DataScientist and what do they do? >>...       1600   \n",
       "1  We all know where it’s going. We just have to ...        880   \n",
       "2  Alexander Barinov: 4 years as CFO in multinati...        255   \n",
       "3                                               sfad        340   \n",
       "4  Ever missed a call while your phone was chargi...        304   \n",
       "\n",
       "                                            Hashtags Time since posted  Likes  \n",
       "0  #MachineLearning #AI #DataAnalytics #DataScien...          11 hours    139  \n",
       "1   #deck .#mac #macintosh#sayhello #apple #steve...           2 hours     23  \n",
       "2  #whoiswho #aitrading #ai #aitradingteam#instat...           2 hours     25  \n",
       "3  #iot #cre#workplace #CDO #bigdata #technology#...           3 hours     49  \n",
       "4  #instamachinelearning #instabigdata#instamarke...           3 hours     30  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8d85700-674d-4b85-8e66-ddb5ac0066df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b7e6d55-b0f9-4abd-a4b6-c307889e37ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caption</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Time since posted</th>\n",
       "      <th>Likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who are #DataScientist and what do they do? &gt;&gt;...</td>\n",
       "      <td>1600</td>\n",
       "      <td>#MachineLearning #AI #DataAnalytics #DataScien...</td>\n",
       "      <td>11 hours</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We all know where it’s going. We just have to ...</td>\n",
       "      <td>880</td>\n",
       "      <td>#deck .#mac #macintosh#sayhello #apple #steve...</td>\n",
       "      <td>2 hours</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alexander Barinov: 4 years as CFO in multinati...</td>\n",
       "      <td>255</td>\n",
       "      <td>#whoiswho #aitrading #ai #aitradingteam#instat...</td>\n",
       "      <td>2 hours</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sfad</td>\n",
       "      <td>340</td>\n",
       "      <td>#iot #cre#workplace #CDO #bigdata #technology#...</td>\n",
       "      <td>3 hours</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ever missed a call while your phone was chargi...</td>\n",
       "      <td>304</td>\n",
       "      <td>#instamachinelearning #instabigdata#instamarke...</td>\n",
       "      <td>3 hours</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Caption  Followers  \\\n",
       "0  Who are #DataScientist and what do they do? >>...       1600   \n",
       "1  We all know where it’s going. We just have to ...        880   \n",
       "2  Alexander Barinov: 4 years as CFO in multinati...        255   \n",
       "3                                               sfad        340   \n",
       "4  Ever missed a call while your phone was chargi...        304   \n",
       "\n",
       "                                            Hashtags Time since posted  Likes  \n",
       "0  #MachineLearning #AI #DataAnalytics #DataScien...          11 hours    139  \n",
       "1   #deck .#mac #macintosh#sayhello #apple #steve...           2 hours     23  \n",
       "2  #whoiswho #aitrading #ai #aitradingteam#instat...           2 hours     25  \n",
       "3  #iot #cre#workplace #CDO #bigdata #technology#...           3 hours     49  \n",
       "4  #instamachinelearning #instabigdata#instamarke...           3 hours     30  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unwanted features\n",
    "data.drop([\"Unnamed: 0\",\"S.No\",\"USERNAME\"],axis=1,inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cf053f6-b632-49d0-b645-ac5bf4b63f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Caption            94 non-null     object\n",
      " 1   Followers          100 non-null    int64 \n",
      " 2   Hashtags           100 non-null    object\n",
      " 3   Time since posted  100 non-null    object\n",
      " 4   Likes              100 non-null    int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f48fb5e5-ad92-461c-acbf-fe01276214d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Time since posted\"] = data[\"Time since posted\"].apply(lambda x:x.replace(\"hours\",\"\")).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8fa3d63-2d8e-4844-aff1-bc8459af3b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use label encoding on catigorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lable = LabelEncoder()\n",
    "cato = [\"Caption\",\"Hashtags\"]\n",
    "for i in cato:\n",
    "    data[i] = lable.fit_transform(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf959cb5-4764-4851-8ac6-d4860c2f792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop([\"Time since posted\",\"Likes\"],axis=1)\n",
    "y = data[[\"Time since posted\",\"Likes\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0b0de09-f47b-4d9f-9e96-cecca8806af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41198361-b2d8-445e-a37e-c6758dc3e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "499162b4-3088-4c68-b60c-5b72d6dd1738",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c79841c-fe89-43ca-9c55-50af047aff65",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2794890f-074a-4dc9-bf97-6be442126a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(test,pread):\n",
    "    mse = mean_squared_error(test,pread)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(test,pread)\n",
    "    r2 = r2_score(test,pread)\n",
    "    \n",
    "    return mse,rmse,mae,r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b01846bd-a55a-443a-aac9-ba8c8ca0bbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestRegressor()\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cf87637-69a2-4700-808e-cfe6138ef9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8275112464053316"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9b0e198-7dee-41dd-9e1a-4d55ac35df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89601280-afd4-4307-b77e-59b5231845ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(623.6572849999999,\n",
       " 24.973131261417738,\n",
       " 12.775500000000003,\n",
       " 0.12161653725837535)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluation(y_test,ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b791fd-c288-46c8-ae01-92933d84e66b",
   "metadata": {},
   "source": [
    "Q-2. Imagine you have a dataset where you have different features like Age , Gender , Height , Weight , BMI , and Blood Pressure and you have to classify the people into different classes like Normal , Overweight , Obesity , Underweight , and Extreme Obesity by using any 4 different classification algorithms. Now you have to build a model which can classify people into different classes. Dataset This is the Dataset You can use this dataset for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d609d109-7e3e-4c03-a709-81584f2b4780",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"ObesityDataSet_raw_and_data_sinthetic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "615ed4e1-1460-4ab8-ac49-32cc3bbd599f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>family_history_with_overweight</th>\n",
       "      <th>FAVC</th>\n",
       "      <th>FCVC</th>\n",
       "      <th>NCP</th>\n",
       "      <th>CAEC</th>\n",
       "      <th>SMOKE</th>\n",
       "      <th>CH2O</th>\n",
       "      <th>SCC</th>\n",
       "      <th>FAF</th>\n",
       "      <th>TUE</th>\n",
       "      <th>CALC</th>\n",
       "      <th>MTRANS</th>\n",
       "      <th>NObeyesdad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.62</td>\n",
       "      <td>64.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Female</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>56.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>77.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Normal_Weight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>87.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Frequently</td>\n",
       "      <td>Walking</td>\n",
       "      <td>Overweight_Level_I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.78</td>\n",
       "      <td>89.8</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>no</td>\n",
       "      <td>2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sometimes</td>\n",
       "      <td>Public_Transportation</td>\n",
       "      <td>Overweight_Level_II</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender   Age  Height  Weight family_history_with_overweight FAVC  FCVC  \\\n",
       "0  Female  21.0    1.62    64.0                            yes   no   2.0   \n",
       "1  Female  21.0    1.52    56.0                            yes   no   3.0   \n",
       "2    Male  23.0    1.80    77.0                            yes   no   2.0   \n",
       "3    Male  27.0    1.80    87.0                             no   no   3.0   \n",
       "4    Male  22.0    1.78    89.8                             no   no   2.0   \n",
       "\n",
       "   NCP       CAEC SMOKE  CH2O  SCC  FAF  TUE        CALC  \\\n",
       "0  3.0  Sometimes    no   2.0   no  0.0  1.0          no   \n",
       "1  3.0  Sometimes   yes   3.0  yes  3.0  0.0   Sometimes   \n",
       "2  3.0  Sometimes    no   2.0   no  2.0  1.0  Frequently   \n",
       "3  3.0  Sometimes    no   2.0   no  2.0  0.0  Frequently   \n",
       "4  1.0  Sometimes    no   2.0   no  0.0  0.0   Sometimes   \n",
       "\n",
       "                  MTRANS           NObeyesdad  \n",
       "0  Public_Transportation        Normal_Weight  \n",
       "1  Public_Transportation        Normal_Weight  \n",
       "2  Public_Transportation        Normal_Weight  \n",
       "3                Walking   Overweight_Level_I  \n",
       "4  Public_Transportation  Overweight_Level_II  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c5fd274-bf0c-4f4c-86ba-8b406e9ac28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender                            0\n",
       "Age                               0\n",
       "Height                            0\n",
       "Weight                            0\n",
       "family_history_with_overweight    0\n",
       "FAVC                              0\n",
       "FCVC                              0\n",
       "NCP                               0\n",
       "CAEC                              0\n",
       "SMOKE                             0\n",
       "CH2O                              0\n",
       "SCC                               0\n",
       "FAF                               0\n",
       "TUE                               0\n",
       "CALC                              0\n",
       "MTRANS                            0\n",
       "NObeyesdad                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c8e4736-cfae-49ac-b55b-9e5cb40ac0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96652b8c-3a28-4abd-a9bc-bae034d96203",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5881ce-3480-4c3a-b219-0dcd23857aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1813026-ed35-401e-9c37-9e4d97e82e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saprate numwerical and catigorical frature\n",
    "catigorical_features = data.select_dtypes(include=\"object\").columns\n",
    "numerical_features = data.select_dtypes(exclude=\"object\").columns\n",
    "print(catigorical_features)\n",
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6078adb2-2802-48a9-abe6-f8667826ac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['NObeyesdad'].value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5775565b-5d6b-4724-8594-a4e24a343ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use label encoding on catigorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lable = LabelEncoder()\n",
    "\n",
    "for i in catigorical_features:\n",
    "    data[i] = lable.fit_transform(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3ba88f-0b5c-4f54-8e93-5a703c31b36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(data.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee6599f-dd9a-4ed7-9e4c-0a32611df0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop('NObeyesdad',axis=1)\n",
    "y = data['NObeyesdad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b0f260-c68f-44b3-97ae-643bb26ef897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saprate numwerical and catigorical frature\n",
    "catigorical_features = x.select_dtypes(include=\"object\").columns\n",
    "numerical_features = x.select_dtypes(exclude=\"object\").columns\n",
    "print(catigorical_features)\n",
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686596e9-98c9-471b-ab55-b298b03e9ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af86dc7-30ce-4134-a081-5d721f42cabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numerical Pipline\n",
    "num_pipline = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\",SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\",StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "cato_pipline = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\",SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"scaler\",StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create Preprocessor object\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num_pipline\",num_pipline,numerical_features),\n",
    "    (\"cato_pipline\",cato_pipline,catigorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1466bf-8cd4-425d-bb62-f60d4cc64cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c30ac0-04ac-49c4-bad6-36094f2cfd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2992686f-98ae-45aa-b816-6697d1592fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d998e9e-d2c8-4d47-8d00-8d4775911557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logastic regression\n",
    "logestic = LogisticRegression(class_weight=\"balanced\")\n",
    "logestic.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e5b0ab-bb34-4f16-aa75-b3474084aa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logestic.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a1ef2b-3982-4c2c-87d8-98a2bcc6a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logestic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbf8352-8ccc-414c-8775-6b85cae6d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6208d2bb-4e24-4971-a298-b4a835808527",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf000a4-ae17-4542-bd3f-aecf8ac325ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector mechine\n",
    "svm = SVC(C=10)\n",
    "svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e6e43d-e6a8-4b2a-9528-26d906d49287",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fbe4d0-4661-4ce5-9f37-f0d68ae51235",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7c8450-b31d-4e8b-9121-e32890a9346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff993314-e3ec-48ff-b99b-b5f6ee88da7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf47cba-512c-47ba-91a3-081d472184c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "tree = DecisionTreeClassifier(max_depth=10,class_weight=\"balanced\",min_samples_split=5)\n",
    "tree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf21154a-30fd-407a-ba4d-bfcf867e457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b4be31-b4d8-42ac-94bc-09e888999c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea947bf-26d9-4a77-aca6-bb6526915f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5638a0-f9b6-4549-a2d1-bbe29da5a2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307319b4-14a2-41fd-96a4-57965a9c3d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "forest = RandomForestClassifier(n_estimators=200,max_depth=10,class_weight=\"balanced\",min_samples_split=5)\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da110130-68af-4bd6-9276-ea2882102e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37723087-cfc0-4a17-bf6d-bf159b5bd2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49ab2ef-fc57-4261-a3ba-33aaa7479e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e078fa18-9fbf-4815-98b1-ff170243a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c17c351-eee4-4d62-b10b-7503ec3bdf6a",
   "metadata": {},
   "source": [
    "Q-3. Imagine you have a dataset where you have different categories of data, Now you need to find the most similar data to the given data by using any 4 different similarity algorithms. Now you have to build a model which can find the most similar data to the given data. Dataset This is the Dataset You can use this dataset for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f91475-3b18-4edf-a55d-d1b19f4c2f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('News_Category_Dataset_v3.json','r') as f:\n",
    "    jdata = f.read()\n",
    "\n",
    "jdata2  = [json.loads(line) for line in jdata.split('\\n') if line]\n",
    "data = pd.DataFrame.from_records(jdata2)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1c82f6-dfde-4a32-9c81-3c02a229b398",
   "metadata": {},
   "source": [
    "Q-4. Imagine you working as a sale manager now you need to predict the Revenue and whether that particular revenue is on the weekend or not and find the Informational_Duration using the Ensemble learning algorithm Dataset This is the Dataset You can use this dataset for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1c4439-dbd9-4890-97ac-a2416c7ded26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"online_shoppers_intention.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e729c630-e775-4026-ad7c-9227ddf20960",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4816b913-3ca1-4e7c-a075-9f94b0365b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6861868a-43cc-410d-bf12-ce6a7ae1383c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6d7707-5ae1-40f9-bfb0-0d8ec4f0f5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Revenue\"] = data[\"Revenue\"].map({True:1,False:0})\n",
    "data['Weekend'] = data['Weekend'].map({True:1,False:0})\n",
    "# saprate numwerical and catigorical frature\n",
    "catigorical_features = data.select_dtypes(include=\"object\").columns\n",
    "numerical_features = data.select_dtypes(exclude=\"object\").columns\n",
    "print(catigorical_features)\n",
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f70bfb8-7866-4b9e-904c-f308d30f1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use label encoding on catigorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lable = LabelEncoder()\n",
    "\n",
    "for i in catigorical_features:\n",
    "    data[i] = lable.fit_transform(data[i])\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(data.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58d94ce-5be0-43d6-87d7-022c65260396",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(\"Revenue\",axis=1)\n",
    "y = data[\"Revenue\"]\n",
    "# saprate numwerical and catigorical frature\n",
    "catigorical_features = x.select_dtypes(include=\"object\").columns\n",
    "numerical_features = x.select_dtypes(exclude=\"object\").columns\n",
    "print(catigorical_features)\n",
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd38274-135b-4f9f-934d-bdd7d2cb82e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "## Numerical Pipline\n",
    "num_pipline = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\",SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\",StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "cato_pipline = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\",SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"scaler\",StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create Preprocessor object\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num_pipline\",num_pipline,numerical_features),\n",
    "    (\"cato_pipline\",cato_pipline,catigorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca1b597-f9f1-43f7-bf94-f83663404a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.20,random_state=42)\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "# RandomForest\n",
    "forest = RandomForestClassifier(n_estimators=250,max_depth=15,class_weight=\"balanced\",min_samples_split=6)\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed2730a-e507-4070-9041-b58083bb6eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c955562-d960-48b5-b65d-ca54f58c602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeec38e-8e07-49fe-8612-d4ca64900740",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4339e9c-a67a-470e-9a61-e4e15d1d0cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagging = BaggingClassifier(n_estimators=50)\n",
    "bagging.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4fb304-a22d-4883-a46e-4db2aeb560cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9f575a-670f-410a-8014-5e45c07d4239",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bagging.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2473645f-11be-4ad9-9e3c-063eb2419fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672e3c53-1f07-401e-9ea6-efa1a2a8f112",
   "metadata": {},
   "source": [
    "Q-5. Uber is a taxi service provider as we know, we need to predict the high booking area using an Unsupervised algorithm and price for the location using a supervised algorithm and use some map function to display the data Dataset This is the Dataset You can use this dataset for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02560a6-5a7b-4a73-9c00-0a7df4cda7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"rideshare_kaggle.csv\")\n",
    "sns.set(rc={\"figure.figsize\":(11,8)})\n",
    "pd.pandas.set_option(\"display.max_columns\",None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24187ed-65bb-4a73-8aa0-cb377309e874",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1815b232-893d-4c9d-9a6d-5ef797972f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c670488-abbd-4505-a117-2695688d617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ce4b1c-d217-4b7e-828c-cf5561adab4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2114e078-4079-498f-bbe0-8242e46b8074",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"price\"] = data[\"price\"].fillna(np.nanmedian(data[\"price\"]))\n",
    "data.drop([\"id\",\"timestamp\",\"product_id\",\"datetime\"],axis=1,inplace=True)\n",
    "# saprate numwerical and catigorical frature\n",
    "catigorical_features = data.select_dtypes(include=\"object\").columns\n",
    "numerical_features = data.select_dtypes(exclude=\"object\").columns\n",
    "print(catigorical_features)\n",
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d674a6-b6ef-4ee2-a10c-75484cfb881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use label encoding on catigorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lable = LabelEncoder()\n",
    "\n",
    "for i in catigorical_features:\n",
    "    data[i] = lable.fit_transform(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3710680-08bf-4d09-b303-c75bf0753982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation_matrix = data.corr().abs()\n",
    "\n",
    "# Set the threshold for correlation value\n",
    "threshold = 0.8\n",
    "\n",
    "# Find highly correlated features\n",
    "correlated_features = set()\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if correlation_matrix.iloc[i, j] >= threshold:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)\n",
    "\n",
    "# Remove the correlated features from the DataFrame\n",
    "data = data.drop(correlated_features, axis=1)\n",
    "\n",
    "# Print the remaining features\n",
    "print(\"Selected Features:\")\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb4fb71-6675-4dda-95ce-86e97f5695a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(\"price\",axis=1)\n",
    "y = data[\"price\"]\n",
    "# saprate numwerical and catigorical frature\n",
    "catigorical_features = x.select_dtypes(include=\"object\").columns\n",
    "numerical_features = x.select_dtypes(exclude=\"object\").columns\n",
    "print(catigorical_features)\n",
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e682999d-c69d-44bc-86fa-bcca837b1ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(55,20))\n",
    "sns.heatmap(data.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695d60ef-06c2-4975-8639-04d46c5891b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numerical Pipline\n",
    "num_pipline = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\",SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\",StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "cato_pipline = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\",SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"scaler\",StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create Preprocessor object\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num_pipline\",num_pipline,numerical_features),\n",
    "    (\"cato_pipline\",cato_pipline,catigorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8d2269-913f-4ea2-8e9f-511cea0883af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.20,random_state=42)\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "forest = RandomForestRegressor(n_estimators=300,max_depth=30,max_samples=10,max_leaf_nodes=8)\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b31077f-6625-4600-820c-84aa973fb58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e5aff6-738b-4007-8f8e-8fd6f14c9586",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest.predict(X_test)\n",
    "model_evaluation(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01d6256-2373-497a-ae4c-461b71bd325e",
   "metadata": {},
   "source": [
    "Q-6. Imagine you have a dataset where you have predicted loan Eligibility using any 4 different classification algorithms. Now you have to build a model which can predict loan Eligibility and you need to find the accuracy of the model and built-in docker and use some library to display that in frontend Dataset This is the Dataset You can use this dataset for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a56447a-5f2f-49a0-88dc-9856c891f152",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"lone data set.csv.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30559370-7b82-4162-abd8-77388d8776e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a8dfe7-2a47-4ee0-95d3-44a271851c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e68198d-0e19-4648-961b-759ca8f70765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as st\n",
    "data[\"Gender\"] = data[\"Gender\"].fillna(st.mode(data[\"Gender\"]))\n",
    "data[\"Married\"] = data[\"Married\"].fillna(st.mode(data[\"Married\"]))\n",
    "data[\"Self_Employed\"] = data[\"Self_Employed\"].fillna(st.mode(data[\"Self_Employed\"]))\n",
    "data[\"LoanAmount\"] = data[\"LoanAmount\"].fillna(np.nanmedian(data[\"LoanAmount\"]))\n",
    "data[\"Loan_Amount_Term\"] = data[\"Loan_Amount_Term\"].fillna(np.nanmedian(data[\"Loan_Amount_Term\"]))\n",
    "data[\"Credit_History\"] = data[\"Credit_History\"].fillna(np.nanmedian(data[\"Credit_History\"]))\n",
    "data.drop([\"Loan_ID\",\"Dependents\"],axis=1,inplace=True)\n",
    "# saprate numwerical and catigorical frature\n",
    "catigorical_features = data.select_dtypes(include=\"object\").columns\n",
    "numerical_features = data.select_dtypes(exclude=\"object\").columns\n",
    "print(catigorical_features)\n",
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72138f53-b53b-4a2d-be54-008c8517b709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use label encoding on catigorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lable = LabelEncoder()\n",
    "\n",
    "for i in catigorical_features:\n",
    "    data[i] = lable.fit_transform(data[i])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de218a-8e9d-4055-928c-d56f8f6c361c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.heatmap(data.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154fde3f-e379-468b-a3a9-5d2f45a20d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(\"Loan_Status\",axis=1)\n",
    "y = data[\"Loan_Status\"]\n",
    "# saprate numwerical and catigorical frature\n",
    "catigorical_features = x.select_dtypes(include=\"object\").columns\n",
    "numerical_features = x.select_dtypes(exclude=\"object\").columns\n",
    "print(catigorical_features)\n",
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597ca83b-3b92-4549-807d-85222404a0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numerical Pipline\n",
    "num_pipline = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\",SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\",StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "cato_pipline = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\",SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"scaler\",StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create Preprocessor object\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num_pipline\",num_pipline,numerical_features),\n",
    "    (\"cato_pipline\",cato_pipline,catigorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e23c5cb-14a1-4ed3-9282-bd1ceb018783",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.20,random_state=42)\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "# logestic Regression\n",
    "logestic = LogisticRegression(class_weight=\"balanced\",C=10)\n",
    "logestic.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292ae112-a865-489e-a4ae-c91f1015dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logestic.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8154967c-aa90-47fe-86fa-1db9a8740f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logestic.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb7140f-71c4-4d06-82b1-c4679456a5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdd8ee1-d95d-4a01-aeca-82e85bb5959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging using tree\n",
    "tree = DecisionTreeClassifier()\n",
    "bagging = BaggingClassifier(tree,n_estimators=50,max_samples=8)\n",
    "bagging.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e848fa-858c-426a-81f7-dae6fb5c07e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bagging.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38972d4d-c3ec-49d0-9a8e-ab439b38367f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bagging.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b9364d-4c2e-434c-bc85-0bfb46950771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adaboost = AdaBoostClassifier(n_estimators=150,learning_rate=0.1)\n",
    "adaboost.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14b9f36-c2a6-4247-a637-f9ddeff5326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "adaboost.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02051fe2-6f25-428c-8ada-3f8eb02847d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = adaboost.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2760be7-0b12-4bb5-bdf0-11bef2bd6b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738f5a9d-b5d6-4738-a5b7-8a2fc74f1446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomforest\n",
    "forest = RandomForestClassifier(n_estimators=120,max_depth=8,class_weight=\"balanced\",max_samples=2,max_leaf_nodes=3)\n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4fb09-de1c-4c5d-b35c-0c9bb5905571",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a4b2ce-7d22-48ec-a74a-2c769bc0bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = forest.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b260c6f7-3068-4b2e-8b02-56fde834b066",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83967752-9d18-454f-afde-00db5f4c13a0",
   "metadata": {},
   "source": [
    "Q-7. Imagine you have a dataset where you need to predict the Genres of Music using an Unsupervised algorithm and you need to find the accuracy of the model, built-in docker, and use some library to display that in frontend Dataset This is the Dataset You can use this dataset for this question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fbb063-828b-4ccb-9295-36ed4e11fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"music.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0810f2f-2325-41e0-9ce6-3da40787f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da817c8-061d-4896-b924-eae173aabc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a29234-46b3-4c5f-b13c-7c54a66c62b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"filename\",axis=1,inplace=True)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b74e78-21fa-49cb-853f-8b7d05d03587",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7b451e-5bbe-4163-9569-f1f2d6d23506",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace=True)\n",
    "data[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ad11de-4e8c-426c-8425-30db7bb10cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saprate numwerical and catigorical frature\n",
    "catigorical_features = data.select_dtypes(include=\"object\").columns\n",
    "numerical_features = data.select_dtypes(exclude=\"object\").columns\n",
    "print(catigorical_features)\n",
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22bc927-bcc6-4360-b81c-c4dbfa1d230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use label encoding on catigorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lable = LabelEncoder()\n",
    "\n",
    "for i in catigorical_features:\n",
    "    data[i] = lable.fit_transform(data[i])\n",
    "plt.figure(figsize=(30,20))\n",
    "sns.heatmap(data.corr(),annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa87bf1-187f-428b-993d-c66218b8b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = data.drop('label',axis=1)\n",
    "y = data['label']\n",
    "# saprate numwerical and catigorical frature\n",
    "catigorical_features = x.select_dtypes(include=\"object\").columns\n",
    "numerical_features = x.select_dtypes(exclude=\"object\").columns\n",
    "print(catigorical_features)\n",
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868164c9-3c03-463b-804b-d48f3d8c0865",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numerical Pipline\n",
    "num_pipline = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\",SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\",StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "cato_pipline = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\",SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"scaler\",StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create Preprocessor object\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num_pipline\",num_pipline,numerical_features),\n",
    "    (\"cato_pipline\",cato_pipline,catigorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7106f7-0535-4a3d-be0f-384390481afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.20,random_state=42)\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "# logestic Regression\n",
    "logestic = LogisticRegression(class_weight=\"balanced\",C=10)\n",
    "logestic.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b922f4-816a-4254-b3ae-c77ec0dd6e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logestic.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b728673f-11ec-4569-b72f-3a6a6fe71150",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logestic.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc171167-b61a-402b-bb54-3252039e9c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# gredient boosting\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f25ce5-2b56-46e1-afb8-c2e8edcceac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gb.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fbdc3b-1e40-49ae-9318-23c8b24ec275",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gb.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe53bd0-4664-4d2e-ba90-85040890a8d0",
   "metadata": {},
   "source": [
    "Q-9. A cyber security agent wants to check the Microsoft Malware so need he came to you as a Machine learning Engineering with Data, You need to find the Malware using a supervised algorithm and you need to find the accuracy of the model. Dataset This is the Dataset You can use this dataset for this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ad31d-bfd0-4448-96b5-b2e714f027ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To big data cannot open in my system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba1ef7-ef72-4c40-82f5-f0049993729f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
